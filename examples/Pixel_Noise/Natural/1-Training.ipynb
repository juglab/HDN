{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Hierarchical DivNoising network for BSD68 dataset corrupted with Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# We import all our dependencies.\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from models.lvae import LadderVAE\n",
    "from boilerplate import boilerplate\n",
    "import lib.utils as utils\n",
    "import training\n",
    "import glob\n",
    "from tifffile import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import urllib\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "Data will be downloaded and stored in the directory ```data```. This data was also used in this [paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Krull_Noise2Void_-_Learning_Denoising_From_Single_Noisy_Images_CVPR_2019_paper.pdf) and many others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder for our data\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "# check if data has been downloaded already\n",
    "zipPath=\"data/BSD68_reproducibility.zip\"\n",
    "if not os.path.exists(zipPath):\n",
    "    #download and unzip data\n",
    "    data = urllib.request.urlretrieve('https://cloud.mpi-cbg.de/index.php/s/pbj89sV6n6SyM29/download', zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we need to follow some preprocessing steps first which will prepare the data for training purposes.\n",
    "We start by reading the training and validation data first from ```data``` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load('data/BSD68_reproducibility_data/train/DCNN400_train_gaussian25.npy')\n",
    "val_data = np.load('data/BSD68_reproducibility_data/val/DCNN400_validation_gaussian25.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the std of Gaussian noise given by ```gaussian_noise_std``` parameter in the next cell. For this dataset, it is 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussian_noise_std = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### We extract overlapping patches of size ```patch_size x patch_size``` from training and validation images.\n",
    "### Usually 128x128 patches work well for most natural image datasets\n",
    "patch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = train_data.shape[2]\n",
    "img_height = train_data.shape[1]\n",
    "num_patches = int(float(img_width*img_height)/float(patch_size**2)*2)\n",
    "train_images = utils.extract_patches(train_data, patch_size, num_patches)\n",
    "val_images = utils.extract_patches(val_data, patch_size, num_patches)\n",
    "train_images = utils.augment_data(train_images) \n",
    "test_images = val_images[:100]\n",
    "img_shape = (train_images.shape[1], train_images.shape[2])\n",
    "print(\"Shape of training images:\", train_images.shape, \"Shape of validation images:\", val_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Hierarchical DivNoising Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>model_name</code> specifies the name of the model with which the weights will be saved and wil be loaded later for prediction.<br>\n",
    "<code>directory_path</code> specifies the directory where the model weights and the intermediate denoising and generation results will be saved. <br>\n",
    "<code>noiseModel</code> specifies a noise model for training. If noisy data is generated synthetically using Gaussian noise, set it to None.<br>\n",
    "<code>batch_size</code> specifies the batch size used for training. The default batch size of $16$ works well for most natural image datasets.<br>\n",
    "<code>virtual_batch</code> specifies the virtual batch size used for training. It divides the <code>batch_size</code> into smaller mini-batches of size <code>virtual_batch</code>. Decrease this if batches do not fit in memory.<br>\n",
    "<code>test_batch_size</code> specifies the batch size used for testing every $1000$ training steps. Decrease this if test batches do not fit in memory, it does not have any consequence on training. It is just for intermediate visual debugging.<br>\n",
    "<code>lr</code> specifies the learning rate.<br>\n",
    "<code>max_epochs</code> specifies the total number of training epochs. Around $150-200$ epochs work well generally.<br>\n",
    "<code>steps_per_epoch</code> specifies how many steps to take per epoch of training. Around $500$ steps work well for most natural image datasets.<br>\n",
    "<code>num_latents</code> specifies the number of stochastic layers. The default setting of $6$ works well for most datasets but quite good results can also be obtained with as less as $4$ layers. However, more stochastic layers may improve performance for some datasets at the cost of increased training time.<br>\n",
    "<code>z_dims</code> specifies the number of bottleneck dimensions (latent space dimensions) at each stochastic layer per pixel. The default setting of $32$ works well for most datasets.<br>\n",
    "<code>blocks_per_layer</code> specifies how many residual blocks to use per stochastic layer. Usually, setting it to be $4$ or more works well. However, more residual blocks improve performance at the cost of increased training time.<br>\n",
    "<code>batchnorm</code> specifies if batch normalization is used or not. Turning it to True is recommended.<br>\n",
    "<code>free_bits</code> specifies the threshold below which KL loss is not optimized for. This prevents the [KL-collapse problem](https://arxiv.org/pdf/1511.06349.pdf%3Futm_campaign%3DRevue%2520newsletter%26utm_medium%3DNewsletter%26utm_source%3Drevue). The default setting of $1.0$ works well for most datasets.<br>\n",
    "\n",
    "**__Note:__** With these settings, training will take approximately $12$ hours on Tesla P100/Titan Xp GPU needing less than 6 GB GPU memory. We optimized the code to run on less GPU memory. For faster training, consider increasing ```virtual_batch_size``` but since we have not tested with different settings of ```virtual_batch_size```, we do not yet know how this affects results. To reduce traing time, also consider reducing either ```num_latents``` or ```blocks_per_layer``` to $4$. These settings will bring down the training time even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"natural\"\n",
    "directory_path = \"./Trained_model/\" \n",
    "noiseModel = None\n",
    "\n",
    "# Training-specific\n",
    "batch_size=16\n",
    "virtual_batch = 8\n",
    "lr=3e-4\n",
    "max_epochs = 400\n",
    "steps_per_epoch = 500\n",
    "test_batch_size=100\n",
    "\n",
    "# Model-specific\n",
    "num_latents = 6\n",
    "z_dims = [32]*int(num_latents)\n",
    "blocks_per_layer = 5\n",
    "batchnorm = True\n",
    "free_bits = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Hierarchical DivNoising Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, data_mean, data_std = boilerplate._make_datamanager(train_images,val_images,\n",
    "                                                                                           test_images,batch_size,\n",
    "                                                                                           test_batch_size)\n",
    "\n",
    "model = LadderVAE(z_dims=z_dims,blocks_per_layer=blocks_per_layer,\n",
    "                  data_mean=data_mean,data_std=data_std,\n",
    "                  noiseModel=noiseModel,device=device,batchnorm=batchnorm,\n",
    "                  free_bits=free_bits,img_shape=img_shape).cuda()\n",
    "\n",
    "model.train() # Model set in training mode\n",
    "\n",
    "training.train_network(model=model,lr=lr,max_epochs=max_epochs,steps_per_epoch=steps_per_epoch,\n",
    "                           directory_path=directory_path,train_loader=train_loader,val_loader=val_loader,\n",
    "                           test_loader=test_loader,virtual_batch=virtual_batch,\n",
    "                           gaussian_noise_std=gaussian_noise_std,model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainHist=np.load(directory_path+\"model/train_loss.npy\")\n",
    "reconHist=np.load(directory_path+\"model/train_reco_loss.npy\")\n",
    "klHist=np.load(directory_path+\"model/train_kl_loss.npy\")\n",
    "valHist=np.load(directory_path+\"model/val_loss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(trainHist,label='training')\n",
    "plt.plot(valHist,label='validation')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(reconHist,label='training')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"reconstruction loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(klHist,label='training')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"KL loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
