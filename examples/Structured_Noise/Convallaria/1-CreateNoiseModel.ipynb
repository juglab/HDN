{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Noise Model\n",
    "We will use pairs of noisy observations $x_i$ and clean signal $s_i$ (created by averaging these noisy, images) to estimate the conditional distribution $p(x_i|s_i)$. Histogram-based and Gaussian Mixture Model-based noise models are generated and saved and later used for training. \n",
    "\n",
    "__Note:__ Noise model can also be generated if noisy data showing same scene is not available. In such a case, we use an approach called ```Bootstrapping```. Take a look at the bootstrapping notebook [here](https://github.com/juglab/PPN2V/blob/master/examples/Convallaria/PN2V/1b_CreateNoiseModel_Bootstrap.ipynb). To understand more about the ```Bootstrapping``` procedure, take a look at the readme [here](https://github.com/juglab/PPN2V)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\") \n",
    "from torch.distributions import normal\n",
    "import matplotlib.pyplot as plt, numpy as np, pickle\n",
    "from scipy.stats import norm\n",
    "from tifffile import imread\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import urllib\n",
    "import os\n",
    "import zipfile\n",
    "from lib.gaussianMixtureNoiseModel import GaussianMixtureNoiseModel\n",
    "from lib import histNoiseModel\n",
    "from lib.utils import plotProbabilityDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "Download the data from https://zenodo.org/record/5160338/files/Struct_Convallaria.zip?download=1. Here we show the pipeline for Convallaria dataset also used in this [paper](https://ieeexplore.ieee.org/abstract/document/9098336). Save the dataset in an appropriate path. For us, the path is the ```data``` folder which exists at ```./```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "# create a folder for our data.\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('./data')\n",
    "\n",
    "# check if data has been downloaded already\n",
    "zipPath=\"./data/Struct_Convallaria.zip\"\n",
    "if not os.path.exists(zipPath):\n",
    "    urllib.request.urlretrieve('https://zenodo.org/record/5160338/files/Struct_Convallaria.zip?download=1', zipPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise model is a characteristic of your camera. The downloaded data folder contains a set of noisy images depicting the same scene 100 times. This is also the data to be denoised. We use the average of these noisy images and treat it as clean image and use the noisy images and average image to create a noise model. Note that instead of using the average images, we could also have used any calibration data from the same microscope since the noise model is completely independent of the sample being imaged. We can either bin the noisy - GT pairs (obtained from noisy calibration images) as a 2-D histogram or fit a GMM distribution to obtain a smooth, parametric description of the noise model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify ```path```, ```dataName```,  ```n_gaussian```, ```n_coeff```\n",
    "The default choices for these values generally work well for most datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=path=\"./data/Struct_Convallaria/\"\n",
    "dataName = 'convallaria' # Name of the noise model \n",
    "n_gaussian = 3 # Number of gaussians to use for Gaussian Mixture Model\n",
    "n_coeff = 2 # No. of polynomial coefficients for parameterizing the mean, standard deviation and weight of Gaussian components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observation = imread(path+\"flower.tif\")\n",
    "nameHistNoiseModel ='HistNoiseModel_'+dataName+'_'+'calibration'\n",
    "nameGMMNoiseModel = 'GMMNoiseModel_'+dataName+'_'+str(n_gaussian)+'_'+str(n_coeff)+'_'+'calibration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data contains 100 images of a static sample.\n",
    "# We estimate the clean signal by averaging all images.\n",
    "\n",
    "signal=np.mean(observation[:, ...],axis=0)[np.newaxis,...]\n",
    "\n",
    "# Let's look the raw data and our pseudo ground truth signal\n",
    "print(signal.shape)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(label='average (ground truth)')\n",
    "plt.imshow(signal[0],cmap='gray')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(label='single raw image')\n",
    "plt.imshow(observation[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating the Histogram Noise Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a histogram based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We set the range of values we want to cover with our model.\n",
    "# The pixel intensities in the images you want to denoise have to lie within this range.\n",
    "# The dataset is clipped to values between 0 and 255.\n",
    "minVal, maxVal = 200, 2300\n",
    "bins = 250\n",
    "\n",
    "# We are creating the histogram.\n",
    "# This can take a minute.\n",
    "histogram = histNoiseModel.createHistogram(bins, minVal, maxVal, observation,signal)\n",
    "\n",
    "# Saving histogram to disc.\n",
    "np.save(path+nameHistNoiseModel+'.npy', histogram)\n",
    "histogramFD=histogram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the histogram-based noise model.\n",
    "plt.xlabel('Observation Bin')\n",
    "plt.ylabel('Signal Bin')\n",
    "plt.imshow(histogramFD**0.25, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the GMM noise model\n",
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a GMM based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_signal=np.min(signal)\n",
    "max_signal=np.max(signal)\n",
    "print(\"Minimum Signal Intensity is\", min_signal)\n",
    "print(\"Maximum Signal Intensity is\", max_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating the noise model training for `n_epoch=2000` and `batchSize=250000` works the best for `Convallaria` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussianMixtureNoiseModel = GaussianMixtureNoiseModel(min_signal = min_signal,\n",
    "                                                                                max_signal =max_signal,\n",
    "                                                                                path=path, weight = None, \n",
    "                                                                                n_gaussian = n_gaussian,\n",
    "                                                                                n_coeff = n_coeff,\n",
    "                                                                                min_sigma = 50, \n",
    "                                                                                device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussianMixtureNoiseModel.train(signal, observation, batchSize = 250000, n_epochs = 2000, learning_rate=0.1, name = nameGMMNoiseModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Histogram-based and GMM-based noise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotProbabilityDistribution(signalBinIndex=100, histogram=histogramFD, gaussianMixtureNoiseModel=gaussianMixtureNoiseModel, min_signal=minVal, max_signal=maxVal, n_bin= bins, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
