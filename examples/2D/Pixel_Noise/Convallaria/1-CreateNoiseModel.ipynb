{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Noise Model using Calibration Data \n",
    "\n",
    "We will use pairs of noisy calibration observations $x_i$ and clean signal $s_i$ (created by averaging these noisy, calibration images) to estimate the conditional distribution $p(x_i|s_i)$. Histogram-based and Gaussian Mixture Model-based noise models are generated and saved and are later used for training.\n",
    "\n",
    "__Note:__ Noise model can also be generated if calibration data is not available. In such a case, we use an approach called ```Bootstrapping```. Take a look at the bootstrapping notebook [here](https://github.com/juglab/PPN2V/blob/master/examples/Convallaria/PN2V/1b_CreateNoiseModel_Bootstrap.ipynb). To understand more about the ```Bootstrapping``` procedure, take a look at the readme [here](https://github.com/juglab/PPN2V)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.distributions import normal\n",
    "import matplotlib.pyplot as plt, numpy as np, pickle\n",
    "from scipy.stats import norm\n",
    "from tifffile import imread\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "#from pn2v import *\n",
    "from lib.gaussianMixtureNoiseModel import GaussianMixtureNoiseModel\n",
    "from lib import histNoiseModel\n",
    "from lib.utils import plotProbabilityDistribution\n",
    "import os\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.random.randn(n_gaussian * 3, n_coeff)\n",
    "weight[n_gaussian:2 * n_gaussian, 1] = np.log(max_signal - min_signal)\n",
    "print(weight)\n",
    "weight = torch.Tensor(weight.astype(np.float32)).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "Download the data from https://zenodo.org/record/5156913/files/Convallaria_diaphragm.zip?download=1. Here we show the pipeline for Convallaria dataset also used in this [paper](https://ieeexplore.ieee.org/abstract/document/9098612/). Save the dataset in an appropriate path. For us, the path is the ```data``` folder which exists at ```./```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('./data')\n",
    "\n",
    "zipPath=\"./data/Convallaria_diaphragm.zip\"\n",
    "if not os.path.exists(zipPath):  \n",
    "    data = urllib.request.urlretrieve('https://zenodo.org/record/5156913/files/Convallaria_diaphragm.zip?download=1', zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise model is a characteristic of your camera. The downloaded data folder contains a set of calibration images (For the Convallaria dataset, it is ```20190726_tl_50um_500msec_wf_130EM_FD.tif``` and the data to be denoised is named ```20190520_tl_25um_50msec_05pc_488_130EM_Conv.tif```). We can either bin the noisy - GT pairs (obtained from noisy calibration images) as a 2-D histogram or fit a GMM distribution to obtain a smooth, parametric description of the noise model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify ```path```, ```dataName```,  ```n_gaussian```, ```n_coeff```.\n",
    "The default choices for these values generally work well for most datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"./data/Convallaria_diaphragm/\"\n",
    "dataName = 'convallaria' # Name of the noise model \n",
    "n_gaussian = 3 # Number of gaussians to use for Gaussian Mixture Model\n",
    "n_coeff = 2 # No. of polynomial coefficients for parameterizing the mean, standard deviation and weight of Gaussian components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observation= imread(path+'20190726_tl_50um_500msec_wf_130EM_FD.tif') # Load the appropriate data\n",
    "nameHistNoiseModel ='HistNoiseModel_'+dataName+'_'+'calibration'\n",
    "nameGMMNoiseModel = 'GMMNoiseModel_'+dataName+'_'+str(n_gaussian)+'_'+str(n_coeff)+'_'+'calibration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data contains 100 images of a static sample.\n",
    "# We estimate the clean signal by averaging all images.\n",
    "\n",
    "signal=np.mean(observation[:, ...],axis=0)[np.newaxis,...]\n",
    "\n",
    "# Let's look the raw data and our pseudo ground truth signal\n",
    "print(signal.shape)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(label='average (ground truth)')\n",
    "plt.imshow(signal[0],cmap='gray')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(label='single raw image')\n",
    "plt.imshow(observation[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Histogram Noise Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a histogram based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We set the range of values we want to cover with our model.\n",
    "# The pixel intensities in the images you want to denoise have to lie within this range.\n",
    "# The dataset is clipped to values between 0 and 255.\n",
    "minVal, maxVal = 234, 7402\n",
    "bins = 256\n",
    "\n",
    "# We are creating the histogram.\n",
    "# This can take a minute.\n",
    "histogram = histNoiseModel.createHistogram(bins, minVal, maxVal, observation,signal)\n",
    "\n",
    "# Saving histogram to disc.\n",
    "np.save(path+nameHistNoiseModel+'.npy', histogram)\n",
    "histogramFD=histogram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the histogram-based noise model.\n",
    "plt.xlabel('Observation Bin')\n",
    "plt.ylabel('Signal Bin')\n",
    "plt.imshow(histogramFD**0.25, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the GMM noise model\n",
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a GMM based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_signal=np.min(signal)\n",
    "max_signal=np.max(signal)\n",
    "print(\"Minimum Signal Intensity is\", min_signal)\n",
    "print(\"Maximum Signal Intensity is\", max_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating the noise model training for `n_epoch=2000` and `batchSize=250000` works the best for `Convallaria` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussianMixtureNoiseModel = GaussianMixtureNoiseModel(min_signal = min_signal,\n",
    "                                                      max_signal = max_signal,\n",
    "                                                      path=path, \n",
    "                                                      weight = None, \n",
    "                                                      n_gaussian = n_gaussian,\n",
    "                                                      n_coeff = n_coeff,\n",
    "                                                      min_sigma = 50,\n",
    "                                                      device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussianMixtureNoiseModel.train(signal, observation, batchSize = 250000, n_epochs = 2000, learning_rate=0.1, name = nameGMMNoiseModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Histogram-based and GMM-based noise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotProbabilityDistribution(signalBinIndex=25, histogram=histogramFD, gaussianMixtureNoiseModel=gaussianMixtureNoiseModel, min_signal=minVal, max_signal=maxVal, n_bin= bins, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('HDN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "fba866763e549ae62100ac47c052b9ebfc70eebe8d34b1a2ae4b12278b60fa10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
